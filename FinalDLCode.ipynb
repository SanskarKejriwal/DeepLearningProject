{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":6903976,"sourceType":"datasetVersion","datasetId":3965364}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda create -n newCondaEnvironment -c cctbx202208 python=3.9 -y\n!source /opt/conda/bin/activate newCondaEnvironment && conda install -c cctbx202208 python -y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!/opt/conda/envs/newCondaEnvironment/bin/python3 --version\n!echo 'print(\"Hello, World!\")' > test.py\n!/opt/conda/envs/newCondaEnvironment/bin/python3 test.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install jupyter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo rm /opt/conda/bin/python3\n!sudo ln -sf /opt/conda/envs/newCondaEnvironment/bin/python3 /opt/conda/bin/python3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo rm /opt/conda/bin/python3.10\n!sudo ln -sf /opt/conda/envs/newCondaEnvironment/bin/python3 /opt/conda/bin/python3.10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo rm /opt/conda/bin/python\n!sudo ln -s /opt/conda/envs/newCondaEnvironment/bin/python3 /opt/conda/bin/python","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r /kaggle/input/requirements/requirements.pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-contrib-python==4.4.0.46 numpy==1.19.3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"DATA_FOLDER = '/kaggle/input/data'\nRESULTS_FOLDER = '/kaggle/working/results'\nTENSORBOARD_BASE_FOLDER = '/kaggle/working/tensorboard'\nINDICES_FILE = '/kaggle/input/data/Data_Entry_2017.csv'\n\nWEIGHT_FILE_NAME = \"weights.best.hdf5\"\n\nMIN_CASES = 1000\n\nIMG_SIZE = (299, 299)\nVGG19_IMG_SIZE = (224,224)\nMOBILENET_IMG_SIZE = (224,224)\nINCEPTIONRESNETV2_IMG_SIZE= (299,299)\nMOBILENETV2_IMG_SIZE = (224,224)\nLARGE_IMG_SIZE = (512,512)\n\n\nLEARNING_RATE = 0.0005\nSYNTHETIC_BATCH_SIZE = 256\nBATCH_SIZE = 16\nDEFAULT_OPTIMIZER = 'adam'\nACCUMULATION_STEPS = int(SYNTHETIC_BATCH_SIZE / BATCH_SIZE)\nVALIDATION_BATCH_SIZE = BATCH_SIZE*2\nEPOCHS = 5\nEARLY_STOPPING_PATIENCE = 2\nRL_PLATEAU_PATIENCE = 2\nWORKERS = 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport gc\n\n# Reset Keras Session\ndef reset_keras():\n  \n    sess = tf.compat.v1.get_default_session()\n    if sess is not None:\n        tf.compat.v1.keras.backend.clear_session()\n        sess.close()\n\n    print(gc.collect())  # If it's done something, you should see a number being outputted\n\n    # Configure the GPU memory options (if needed)\n    config = tf.compat.v1.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = 1\n    config.gpu_options.visible_device_list = \"0\"\n    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"from itertools import chain\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nall_labels = None\n\ndef load_metadata(data_folder=DATA_FOLDER,\n                  metadata_file=INDICES_FILE):\n   \n    metadata = pd.read_csv(os.path.join(data_folder, metadata_file))\n    file_system_scan = {os.path.basename(x): x for x in\n                        glob(os.path.join(data_folder, 'images*', 'images','*.png'))}\n    if len(file_system_scan) != metadata.shape[0]:\n        raise Exception(\n            'ERROR: Different number metadata records and png files.'.format())\n\n    metadata['path'] = metadata['Image Index'].map(file_system_scan.get)\n    print('Total x-ray records:{}.'.format((metadata.shape[0])))\n\n    return metadata\n\n\ndef preprocess_metadata(metadata, minimum_cases=MIN_CASES):\n\n\n    metadata['Finding Labels'] = metadata['Finding Labels'].map(\n        lambda x: x.replace('No Finding', ''))\n\n    labels = np.unique(\n        list(chain(*metadata['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n    labels = [x for x in labels if len(x) > 0]\n\n    for c_label in labels:\n        if len(c_label) > 1:  # leave out empty labels\n            metadata[c_label] = metadata['Finding Labels'].map(\n                lambda finding: 1.0 if c_label in finding else 0)\n\n    labels = [c_label for c_label in labels if metadata[c_label].sum()\n              > minimum_cases]\n\n    sample_weights = metadata['Finding Labels'].map(\n        lambda x: len(x.split('|')) if len(x) > 0 else 0).values + 4e-2\n    sample_weights /= sample_weights.sum()\n    metadata = metadata.sample(80000, weights=sample_weights)\n\n    labels_count = [(c_label, int(metadata[c_label].sum()))\n                    for c_label in labels]\n\n    print('Labels ({}:{})'.format((len(labels)), (labels_count)))\n    print('Total x-ray records:{}.'.format((metadata.shape[0])))\n\n    all_labels = labels\n    \n    return metadata, labels\n\n\ndef stratify_train_test_split(metadata):\n   \n    stratify = metadata['Finding Labels'].map(lambda x: x[:4])\n    train, valid = train_test_split(metadata,\n                                    test_size=0.25,\n                                    random_state=2018,\n                                    stratify=stratify)\n    return train, valid\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Accumulation","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import Optimizer\n\nclass AdamAccumulate(Optimizer):\n    def __init__(self, lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0., amsgrad=False, accum_iters=1, **kwargs):\n        if accum_iters < 1:\n            raise ValueError('accum_iters must be >= 1')\n        super(AdamAccumulate, self).__init__(**kwargs)\n        self.lr = lr\n        self.beta_1 = beta_1\n        self.beta_2 = beta_2\n        self.amsgrad = amsgrad\n        self.accum_iters = accum_iters\n        self.accum_iters_float = float(accum_iters)\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = []\n\n        completed_updates = tf.floor_div(tf.cast(self.iterations, tf.float32), self.accum_iters_float)\n\n        lr = self.lr\n\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * completed_updates))\n\n        t = completed_updates + 1\n\n        lr_t = lr * (tf.sqrt(1. - tf.pow(self.beta_2, t)) / (1. - tf.pow(self.beta_1, t)))\n\n        update_switch = tf.equal((self.iterations + 1) % self.accum_iters, 0)\n        update_switch = tf.cast(update_switch, tf.float32)\n\n        ms = [tf.zeros(tf.shape(p), dtype=p.dtype) for p in params]\n        vs = [tf.zeros(tf.shape(p), dtype=p.dtype) for p in params]\n        gs = [tf.zeros(tf.shape(p), dtype=p.dtype) for p in params]\n\n        if self.amsgrad:\n            vhats = [tf.zeros(tf.shape(p), dtype=p.dtype) for p in params]\n        else:\n            vhats = [tf.zeros(1, dtype=p.dtype) for p in params]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat, tg in zip(params, grads, ms, vs, vhats, gs):\n            sum_grad = tg + g\n            avg_grad = sum_grad / self.accum_iters_float\n\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * avg_grad\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * tf.square(avg_grad)\n\n            if self.amsgrad:\n                vhat_t = tf.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t / (tf.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(tf.assign(vhat, (1 - update_switch) * vhat + update_switch * vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (tf.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(tf.assign(m, (1 - update_switch) * m + update_switch * m_t))\n            self.updates.append(tf.assign(v, (1 - update_switch) * v + update_switch * v_t))\n            self.updates.append(tf.assign(tg, (1 - update_switch) * sum_grad))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(tf.assign(p, (1 - update_switch) * p + update_switch * new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': self.lr, 'beta_1': self.beta_1, 'beta_2': self.beta_2, 'decay': self.decay, 'epsilon': self.epsilon, 'amsgrad': self.amsgrad}\n        base_config = super(AdamAccumulate, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\ndef calculate_accuracies(results, labels=None, run_timestamp='unspecified'):\n   \n    if labels is None:\n        return\n\n    print(classification_report(labels, results))\n    clf_report = classification_report(labels, results, output_dict=True)\n    clf_filename = f'classification_report_{run_timestamp}.json'\n    clf_path = os.path.join(RESULTS_FOLDER, clf_filename)\n    df = pd.DataFrame(clf_report)\n    df.to_json(clf_path, orient='columns')\n    print(f'Classification report saved to {clf_path}')\n\n    conf_matrix = confusion_matrix(labels, results)\n    conf_matrix_filename = f'confusion_matrix_{run_timestamp}.csv'\n    conf_matrix_path = os.path.join(RESULTS_FOLDER,\n                                    conf_matrix_filename)\n    df = pd.DataFrame(conf_matrix)\n    df.to_csv(conf_matrix_path, index=True)\n    print(f'Confusion matrix saved to {conf_matrix_path}')\n\n    \ndef plot_train_metrics(model_history, model_name, results_folder, run_timestamp='unspecified'):\n\n    train_losses = model_history.history['loss']\n    val_losses = model_history.history['val_loss']\n    final_val_loss = val_losses[-1]\n\n    train_acc = model_history.history['binary_accuracy']\n    val_acc = model_history.history['val_binary_accuracy']\n    final_val_acc = val_acc[-1]\n\n    loss_filename = f'{model_name}_loss_plot_val_loss_{final_val_loss:.4f}_val_acc_{final_val_acc:.4f}_{run_timestamp}.png'\n    loss_fig_path = os.path.join(results_folder, loss_filename)\n    acc_filename = f'{model_name}_accuracy_plot_val_loss_{final_val_loss:.4f}_val_acc_{final_val_acc:.4f}_{run_timestamp}.png'\n    acc_fig_path = os.path.join(results_folder, acc_filename)\n\n    plt.plot(train_losses)\n    plt.plot(val_losses)\n    plt.xticks(np.arange(0, len(train_losses), step=1))\n    plt.xlabel('Epoch Number')\n    plt.ylabel('Loss')\n    plt.title(f'{model_name} Model\\nRun time: {run_timestamp}')\n    plt.legend(('Training', 'Validation'))\n    plt.savefig(loss_fig_path)\n\n    # clear axes and figure to reset for next plot\n    plt.cla()\n    plt.clf()\n\n    # generate and save accuracy plot\n    plt.plot(train_acc)\n    plt.plot(val_acc)\n    plt.xticks(np.arange(0, len(train_acc), step=1))\n    plt.xlabel('Epoch Number')\n    plt.ylabel('Accuracy')\n    plt.title(f'{model_name} Model\\nRun time: {run_timestamp}')\n    plt.legend(('Training', 'Validation'))\n    plt.savefig(acc_fig_path)\n\n    return loss_fig_path, acc_fig_path\n\n\ndef save_model(model, model_history, model_name, results_folder, run_timestamp='unspecified'):\n   \n    final_val_loss = model_history.history['val_loss'][-1]\n    final_val_acc = model_history.history['val_binary_accuracy'][-1]\n\n    json_filename = f'{model_name}_config_val_loss_{final_val_loss:.4f}_val_acc_{final_val_acc:.4f}_{run_timestamp}.json'\n    output_json = os.path.join(\n        results_folder, json_filename)\n    with open(output_json, 'w') as json_file:\n        json_file.write(model.to_json())\n\n    weights_filename = f'{model_name}_weights_val_loss_{final_val_loss:.4f}_val_acc_{final_val_acc:.4f}_{run_timestamp}.hdf5'\n    output_weights = os.path.join(results_folder, weights_filename)\n    model.save_weights(output_weights)\n\n    symlink_path = os.path.join(\n        results_folder, f'{model_name}_weights_latest.hdf5')\n    try:\n        os.symlink(output_weights, symlink_path)\n    except FileExistsError:\n        os.remove(symlink_path)\n        os.symlink(output_weights, symlink_path)\n    print(f'Created symbolic link to final weights -> {symlink_path}')\n\n    return output_json, output_weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"\nimport os\nfrom time import time\nimport datetime\n\nfrom time import time\nimport datetime\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input as MobileNet_preprocess_input\nfrom tensorflow.keras.applications.vgg19 import preprocess_input as VGG19_preprocess_input\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as InceptionResNetV2_preprocess_input\nfrom tensorflow.keras.layers import Flatten, Dense, LocallyConnected2D, MaxPooling2D, Input, Conv2D, AvgPool2D, Lambda, Dropout, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, multiply, BatchNormalization\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nfrom sklearn.metrics import roc_curve, auc\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\npredictionList=[]\nAUC_SCORES=[]\nTEST_Y=[]\nLABELS=[]\nRUN_TIMESTAMP = datetime.datetime.now().isoformat('-')\nattention_models = []\n\n\nbase_models = [\n    [VGG19, VGG19_IMG_SIZE, VGG19_preprocess_input],\n    [MobileNet, MOBILENET_IMG_SIZE, MobileNet_preprocess_input],[InceptionResNetV2, INCEPTIONRESNETV2_IMG_SIZE,\n     InceptionResNetV2_preprocess_input],\n]\n\n\ndef create_data_generator(dataset,\n                          labels,\n                          batch_size,\n                          preprocessing_function,\n                          color_mode=\"rgb\",\n                          target_size=IMG_SIZE):\n   \n    dataset['newLabel'] = dataset.apply(\n        lambda x: x['Finding Labels'].split('|'), axis=1)\n\n    image_generator = ImageDataGenerator(samplewise_center=True,\n                                         samplewise_std_normalization=True,\n                                         horizontal_flip=True,\n                                         vertical_flip=False,\n                                         height_shift_range=0.05,\n                                         width_shift_range=0.1,\n                                         rotation_range=5,\n                                         shear_range=0.1,\n                                         fill_mode='reflect',\n                                         zoom_range=0.15,\n                                         preprocessing_function=preprocessing_function)\n\n    dataset_generator = image_generator.flow_from_dataframe(dataframe=dataset,\n                                                            directory=None,\n                                                            x_col='path',\n                                                            y_col='newLabel',\n                                                            class_mode='categorical',\n                                                            classes=labels,\n                                                            target_size=target_size,\n                                                            color_mode=color_mode,\n                                                            batch_size=batch_size)\n\n    return dataset_generator\n\n\ndef _create_attention_model(frozen_model, labels, optimizer='adam'):\n   \n    frozen_features = Input(frozen_model.get_output_shape_at(0)[\n        1:], name='feature_input')\n    frozen_depth = frozen_model.get_output_shape_at(0)[-1]\n    new_features = BatchNormalization()(frozen_features)\n\n    attention_layer = Conv2D(128, kernel_size=(1, 1), padding='same',\n                             activation='elu')(new_features)\n    attention_layer = Conv2D(32, kernel_size=(1, 1), padding='same',\n                             activation='elu')(attention_layer)\n    attention_layer = Conv2D(16, kernel_size=(1, 1), padding='same',\n                             activation='elu')(attention_layer)\n    attention_layer = AvgPool2D((2, 2), strides=(1, 1), padding='same')(\n        attention_layer)  # smooth results\n    attention_layer = Conv2D(1,\n                             kernel_size=(1, 1),\n                             padding='valid',\n                             activation='sigmoid')(attention_layer)\n\n    up_c2_w = np.ones((1, 1, 1, frozen_depth))\n    up_c2 = Conv2D(frozen_depth, kernel_size=(1, 1), padding='same',\n                   activation='linear', use_bias=False, weights=[up_c2_w])\n    up_c2.trainable = False\n    attention_layer = up_c2(attention_layer)\n\n    mask_features = multiply([attention_layer, new_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attention_layer)\n\n    gap = Lambda(lambda x: x[0]/x[1],\n                 name='RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.5)(gap)\n    dr_steps = Dropout(0.5)(Dense(128, activation='elu')(gap_dr))\n    out_layer = Dense(len(labels), activation='sigmoid')(dr_steps)\n\n    attention_model = Model(inputs=[frozen_features], outputs=[\n        out_layer], name='attention_model')\n\n    attention_model.compile(optimizer=optimizer, loss='binary_crossentropy',\n                            metrics=['binary_accuracy'])\n\n    return attention_model\n\n\ndef _create_base_model(Model, labels, input_shape, trainable=False, weights=\"imagenet\"):\n    \n    base_model = Model(weights=weights,\n                       include_top=False,\n                       input_shape=input_shape)\n    base_model.trainable = trainable\n    base_model(tf.keras.Input(input_shape))\n    return base_model\n\n\ndef create_simple_model(base_model, labels, optimizer='adam'):\n  \n\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(512))\n    model.add(Dropout(0.5))\n    model.add(Dense(len(labels), activation='sigmoid'))\n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy',\n                  metrics=['binary_accuracy', 'mae'])\n    print(f'{model.summary()}')\n    return model\n\n\ndef create_attention_model(base_model, labels, optimizer='adam'):\n   \n\n    attention_model = _create_attention_model(\n        base_model, labels, optimizer=optimizer)\n\n    model = Sequential(name='combined_model')\n    model.add(base_model)\n    model.add(attention_model)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy',\n                  metrics=['binary_accuracy'])\n    \n    attention_models.append(model)\n\n    print(f'{model.summary()}')\n\n    return model\n\n\ndef fit_model(model, model_name, train, valid):\n   \n    results_folder = os.path.join(RESULTS_FOLDER, model_name)\n    if not os.path.exists(results_folder):\n        os.makedirs(results_folder)\n\n    weight_path = os.path.join(results_folder, WEIGHT_FILE_NAME)\n\n    checkpoint = ModelCheckpoint(weight_path,\n                                 monitor='val_loss',\n                                 verbose=1,\n                                 save_best_only=True,\n                                 mode='min',\n                                 save_weights_only=True)\n\n    early = EarlyStopping(monitor=\"val_loss\",\n                          mode=\"min\",\n                          patience=EARLY_STOPPING_PATIENCE)\n\n    tensorboard = TensorBoard(log_dir=os.path.join(\n        RESULTS_FOLDER, TENSORBOARD_BASE_FOLDER, model_name))\n\n    dynamicLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                                  patience=2, min_lr=LEARNING_RATE/100)\n\n    callbacks_list = [tensorboard, checkpoint, dynamicLR, early]\n\n    history = model.fit(  train,\n                          validation_data=valid,\n                          validation_steps=valid.samples//valid.batch_size,\n                          steps_per_epoch=train.samples//train.batch_size,\n                          epochs=EPOCHS,\n                          callbacks=callbacks_list,\n                          use_multiprocessing=True,\n                          workers=WORKERS)\n\n    loss_fig_path, acc_fig_path = plot_train_metrics(\n        history, model_name, results_folder,  RUN_TIMESTAMP)\n    print(f'Saved loss plot -> {loss_fig_path}')\n    print(f'Saved accuracy plot -> {acc_fig_path}')\n\n    json_path, weights_path = save_model(\n        model, history, model_name, results_folder, RUN_TIMESTAMP)\n    print(f'Saved json config -> {json_path}')\n    print(f'Saved weights -> {weights_path}')\n\n    return model\n\n\ndef plot_ROC(labels, test_Y, pred_Y, model_name):\n    aucScores = []\n    fig, c_ax = plt.subplots(1, 1, figsize=(9, 9))\n    for (idx, c_label) in enumerate(labels):\n        fpr, tpr, thresholds = roc_curve(\n            test_Y[:, idx].astype(int), pred_Y[:, idx])\n        c_ax.plot(fpr, tpr, label='%s (AUC:%0.2f)' % (c_label, auc(fpr, tpr)))\n        aucScores.append(auc(fpr,tpr))\n    c_ax.legend()\n    c_ax.set_title(model_name+' ROC Curve')\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n\n    ROC_image_file_path = os.path.join(\n        RESULTS_FOLDER, model_name, model_name + '_ROC.png')\n    AUC_SCORES.append(aucScores)\n    fig.savefig(ROC_image_file_path)\n    print('Saved ROC plot at'+ROC_image_file_path)\n\n\ndef train_model(_Model, input_shape, transfer_learing,\n                preprocessing_function,\n                train, valid, labels,\n                extend_model_callback, optimizer,\n                name_prefix, weights=\"imagenet\"):\n\n    if not transfer_learing:\n        weights = None\n\n    train_generator = create_data_generator(\n        train, labels, BATCH_SIZE, preprocessing_function, target_size=input_shape)\n    validation_generator = create_data_generator(\n        valid, labels, VALIDATION_BATCH_SIZE, preprocessing_function, target_size=input_shape)\n\n    test_X, test_Y = next(validation_generator)\n\n    baseModel = _create_base_model(_Model,\n                                   labels,\n                                   test_X.shape[1:],\n                                   trainable=not transfer_learing,\n                                   weights=weights)\n\n    model = extend_model_callback(baseModel, labels, optimizer)\n    model_name = f'{name_prefix}_{baseModel.name}'\n\n    model = fit_model(model, model_name,\n                      train_generator, validation_generator)\n\n    # print ROC\n    test_X, test_Y = next(create_data_generator(\n        valid, labels, 10000, None, target_size=input_shape))\n    pred_Y = model.predict(test_X, batch_size=32, verbose=True)\n    TEST_Y.append(test_Y)\n    predictionList.append(pred_Y)\n    \n    plot_ROC(labels, test_Y, pred_Y, model_name)\n\n\ndef plot_model_ROC(_Model, input_shape, transfer_learing,\n                preprocessing_function,\n                train, valid, labels,\n                extend_model_callback, optimizer,\n                name_prefix, weights=\"imagenet\"):\n\n    test_X, test_Y = next(create_data_generator(\n        valid, labels, 10000, None, target_size=input_shape))\n\n    baseModel = _create_base_model(_Model,\n                                   labels,\n                                   test_X.shape[1:],\n                                   trainable=False,\n                                   weights=None)\n\n    model = extend_model_callback(baseModel, labels, optimizer)\n\n    model_name = name_prefix+'_' + baseModel.name\n\n    weights = os.path.join(RESULTS_FOLDER,\n                           model_name, 'weights.best.hdf5')\n\n    print('Loading '+weights)\n    model.load_weights(weights, by_name=True)\n    model.trainable = False\n\n    pred_Y = model.predict(test_X, batch_size=32, verbose=True)\n\n    plot_ROC(labels, test_Y, pred_Y, model_name)\n\ndef loop_in_combinations(callback, image_size=None, transfer_learing=True, use_preprocess_input=False):\n\n\n    metadata = load_metadata()\n    metadata, labels = preprocess_metadata(metadata)\n    train, valid = stratify_train_test_split(metadata)\n    LABELS.append(labels)\n    # for these image sizes, we don't need gradient_accumulation to achieve BATCH_SIZE = 256\n    optimizer = 'adam'\n    if DEFAULT_OPTIMIZER != optimizer:\n        optimizer = AdamAccumulate(\n            lr=LEARNING_RATE, accum_iters=ACCUMULATION_STEPS)\n\n    unfrozen = 'unfrozen_'\n    if transfer_learing:\n        unfrozen = ''\n    custom_layers = [\n        [create_attention_model, unfrozen+'Attention'],\n    ]\n\n    for [custome_layer, name_prefix] in custom_layers:\n        for [_Model, input_shape, preprocess_input] in base_models:\n            _image_size = image_size\n            if _image_size is None:\n                _image_size = input_shape\n            _preprocess_input = preprocess_input\n            if not use_preprocess_input:\n                _preprocess_input = None\n            callback(_Model, _image_size, transfer_learing, _preprocess_input,\n                        train, valid, labels,\n                        custome_layer, optimizer, name_prefix)\n\ndef plot_ROCs(image_size=None, transfer_learing=True, use_preprocess_input=False):\n\n    loop_in_combinations(plot_model_ROC, image_size, transfer_learing, use_preprocess_input)\n\ndef train_multiple_networks(image_size=None, transfer_learing=True, use_preprocess_input=False):\n   \n    loop_in_combinations(train_model, image_size, transfer_learing, use_preprocess_input)\n\n\nreset_keras()\ntrain_multiple_networks(use_preprocess_input = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble Method","metadata":{}},{"cell_type":"code","source":"test_Y=TEST_Y[1]\nall_labels=LABELS[0]\nweightList = [0.1, 0.8, 0.1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createROC(all_labels, test_Y, pred_Y, filename=\"roc.png\"):\n    aucScores = []\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    for (idx, c_label) in enumerate(all_labels):\n        fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n        aucScores.append(auc(fpr,tpr))\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    fig.savefig(filename)\n    return aucScores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MaxVoteEnsemble(predictionList):\n    ensemble_preds = np.maximum(*predictionList)\n    return ensemble_preds\n\ndef SimpleAverageEnsemble(predictionList):\n    ensemble_preds = np.zeros(predictionList[0].shape)\n    for pred in predictionList:\n        ensemble_preds += pred\n    \n    ensemble_preds /= len(predictionList)\n    return ensemble_preds\n\ndef WeightedAverageEnsemble(predictionList, weightList):\n    ensemble_preds = np.zeros(predictionList[0].shape)\n    for pred, weight in zip(predictionList, weightList):\n        ensemble_preds += pred*weight\n    return ensemble_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_vote_ensemble_preds = MaxVoteEnsemble(predictionList)\nsimple_ensemble_preds = SimpleAverageEnsemble(predictionList)\nweighted_ensemble_preds = WeightedAverageEnsemble(predictionList, weightList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxvoteensembleAUC = createROC(all_labels, test_Y, max_vote_ensemble_preds, filename=\"max_vote_ensemble_roc.png\")\nweightedensembleAUC = createROC(all_labels, test_Y, weighted_ensemble_preds, filename=\"weighted_ensemble_roc.png\")\nsimpleensembleAUC = createROC(all_labels, test_Y, simple_ensemble_preds, filename=\"simple_ensemble_roc.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaryDF = pd.DataFrame(\n    {'Class':all_labels,\n    'Mobilenet': AUC_SCORES[1],\n    'Resnet': AUC_SCORES[2],\n    'VGG': AUC_SCORES[0],\n    'Avg Ensemble': simpleensembleAUC,\n    'Wght Avg Ensemble': weightedensembleAUC,\n    'Max Vote Ensemble': maxvoteensembleAUC}\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaryDF.round(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaryDF.to_csv('my_data.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nwith open('predictionData.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(predictionList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('AUCData.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(AUC_SCORES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}